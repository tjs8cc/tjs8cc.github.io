<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tyler Smith on Tyler Smith</title>
    <link>/</link>
    <description>Recent content in Tyler Smith on Tyler Smith</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Measuring Measure for Measure</title>
      <link>/post/measuring-measure-for-measure/</link>
      <pubDate>Mon, 25 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/measuring-measure-for-measure/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;purpose&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Purpose&lt;/h1&gt;
&lt;p&gt;This is a work in progress, but I’d like to post a summary
and my thoughts on Shakespeare’s &lt;em&gt;Measure for Measure&lt;/em&gt; and then
use it to perform some basic Natural Language Processing (NLP)&lt;/p&gt;
&lt;p&gt;Note: if I end up doing a sentiment analysis, the sentiment libraries
I’m aware of would not really be appropriate for early modern
English.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;word-frequencies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Word Frequencies&lt;/h2&gt;
&lt;p&gt;Load &lt;em&gt;Measure for Measure&lt;/em&gt; from the Gutenberg Project:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mm &amp;lt;- gutenberg_download(1126)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tokenize&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_mm &amp;lt;- mm %&amp;gt;%
  unnest_tokens(word, text) %&amp;gt;%
  anti_join(stop_words)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;count&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mm_count &amp;lt;- tidy_mm %&amp;gt;%
              count(word, sort = TRUE)
kable(head(mm_count)) %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
word
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
n
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
duke
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
261
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
angelo
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
168
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
isabella
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
159
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
sir
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
135
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
lucio
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
132
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
provost
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
116
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Notes on The Elements of Statistical Learning</title>
      <link>/post/notes-on-the-elements-of-statistical-learning/</link>
      <pubDate>Thu, 21 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/notes-on-the-elements-of-statistical-learning/</guid>
      <description>&lt;div id=&#34;purpose&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Purpose&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;The Elements of Statistical Learning&lt;/em&gt; is the best resource I’ve
found for understanding modern statistical and machine learning techniques.
These techniques aim to answer problems of the following kind: what’s the
best approximation to the conditional expectation function &lt;span class=&#34;math inline&#34;&gt;\(f(x) = E[Y|X]\)&lt;/span&gt;?
Or more generally, what is our best guess for &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; given what we know about
&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;? Where ‘best’ can be defined in a number of ways, but usually results
in trying to approximate the conditional expectation function (CEF). A critical
assumption made in most of these techniques is that the error is additive,
so that the general model is &lt;span class=&#34;math display&#34;&gt;\[ Y = f(x) + \epsilon\]&lt;/span&gt; along with some assumptions
about how &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is distributed. The assumptions on &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; should not
be considered an after thought; often they are the most important part of the
model, especially when you’re interested in causal questions (see &lt;em&gt;Mostly
Harmless Econometrics&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;I want to summarize and replicate some of the results from their book (as well
as from their introductory book &lt;em&gt;An Introduction to Statistical Learning&lt;/em&gt;)
to get a better handle on these techniques.&lt;/p&gt;
&lt;div id=&#34;the-bias-variance-tradeoff&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Bias-Variance Tradeoff&lt;/h2&gt;
&lt;p&gt;A theme running throughout &lt;em&gt;The Elements of Statistical Learning&lt;/em&gt; is that any
estimation strategy must make a choice between how much bias or variance to
tolerate. Hastie et. al. have a nice discussion of this in their overview
chapter. They note that the mean squared error of an estimator is
&lt;span class=&#34;math display&#34;&gt;\[MSE(\hat{f}(x)) = Var(\hat{f}(x))+ [Bias(\hat{f}(x))]^2 + Var(\epsilon)\]&lt;/span&gt;
The variance of &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the irreducible error. There’s nothing that our
model can do to reduce this error. The bias and variance of &lt;span class=&#34;math inline&#34;&gt;\(\hat{f}(x)\)&lt;/span&gt; can
however be reduced. Roughly, the bias results from misspecifying the CEF and the
variance of &lt;span class=&#34;math inline&#34;&gt;\(\hat{f}(x)\)&lt;/span&gt; is due to sampling error, which can be reduced by
increasing the sample size. So it would seem obvious that we should choose
correctly specified models to get the best predictions, but what Hastie et.
al. show is that often times we can do better by intentionally biasing our model
if the variance is reduced enough in exchange.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tree-based-methods&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tree-based Methods&lt;/h2&gt;
&lt;p&gt;The tree method is very intuitive. We would like to approximate a function &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; by
partitioning its domain and approximating the function over each region with a
constant equal to the average value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; in each region. Deciding how to
partition the domain results in different trees.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Carseats = data.frame(Carseats, High)
tree.carseats = tree(High ~ ShelveLoc + Price, Carseats )
summary(tree.carseats)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Classification tree:
## tree(formula = High ~ ShelveLoc + Price, data = Carseats)
## Number of terminal nodes:  10 
## Residual mean deviance:  0.9325 = 363.7 / 390 
## Misclassification error rate: 0.2325 = 93 / 400&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(tree.carseats, type = c(&amp;quot;uniform&amp;quot;))
text(tree.carseats, pretty = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-06-21-notes-on-the-elements-of-statistical-learning_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Predicting Blood Donations: Part 1</title>
      <link>/post/predicting-blood-donations-part-1/</link>
      <pubDate>Thu, 21 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/predicting-blood-donations-part-1/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;purpose&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Purpose&lt;/h2&gt;
&lt;p&gt;This post shows some basic R usage, data exploration, and visualization methods.
In a future post I’ll explore some quantitative methods.&lt;/p&gt;
&lt;div id=&#34;obtaining-data-in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Obtaining data in R&lt;/h3&gt;
&lt;p&gt;R has a useful function called &lt;code&gt;download.file&lt;/code&gt;, which I show here for future
reference. Using &lt;code&gt;method = curl&lt;/code&gt;, and maybe the &lt;code&gt;extra&lt;/code&gt; option to pass additional
arguments, I can download data from the DrivenData website&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;training_data_url &amp;lt;- &amp;quot;https://s3.amazonaws.com/drivendata/data/2/public/
                      9db113a1-cdbe-4b1c-98c2-11590f124dd8.csv&amp;quot;
train_file &amp;lt;- &amp;quot;../../data/training.csv&amp;quot;
if(!file.exists(train_file)){
  download.file(training_data_url, train_file, method = &amp;quot;curl&amp;quot;)
}

test_data_url &amp;lt;- &amp;quot;https://s3.amazonaws.com/drivendata/data/2/public/
                  5c9fa979-5a84-45d6-93b9-543d1a0efc41.csv&amp;quot;
test_file &amp;lt;- &amp;quot;../../data/test.csv&amp;quot;
if(!file.exists(test_file)){
  download.file(test_data_url, test_file, method = &amp;quot;curl&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, to look at the first few rows of data, I run:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;training &amp;lt;- read.csv(&amp;quot;../../data/training.csv&amp;quot;, row.names = 1)
names(training) &amp;lt;- c(&amp;quot;last&amp;quot;, &amp;quot;number&amp;quot;, &amp;quot;volume&amp;quot;, &amp;quot;first&amp;quot;, &amp;quot;donated07&amp;quot;)
kable(head(training)) %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
last
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
number
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
volume
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
first
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
donated07
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
619
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
98
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
664
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3250
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
441
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
160
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
358
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
335
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;div id=&#34;read.csv-vs-read_csv&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;code&gt;read.csv&lt;/code&gt; vs &lt;code&gt;read_csv&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;I chose to use &lt;code&gt;read.csv&lt;/code&gt; here since this data set came with row names. But in
general, &lt;code&gt;read_csv&lt;/code&gt; loads data faster and reads the data into a &lt;code&gt;tibble&lt;/code&gt;, and
&lt;code&gt;tibbles&lt;/code&gt; do not have row names.&lt;code&gt;read.csv&lt;/code&gt; reads the data into a &lt;code&gt;data.frame&lt;/code&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-the-data-in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exploring the data in R&lt;/h3&gt;
&lt;p&gt;As a first pass, let’s graph the histograms and scatter plots of the co-variates.
A quick way to do this is to plot a scatter matrix. I’ll color by the outcome
variable &lt;code&gt;donated07&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggpairs(training, aes(colour=factor(donated07)), 
        diag = list(continuous = wrap(&amp;#39;barDiag&amp;#39;, bins = 20)),
        columns = 1:(ncol(training)-1), progress = F) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-06-21-predicting-blood-donations-part-1_files/figure-html/scatter_matrix-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice that &lt;code&gt;number&lt;/code&gt; and &lt;code&gt;volume&lt;/code&gt; are perfectly correlated, which means that
one of them needs to be dropped in any regression. The remaining co-variates
do not look strongly correlated. It also looks like &lt;code&gt;first&lt;/code&gt; might be top-coded
at 100 months.&lt;/p&gt;
&lt;p&gt;People who were more likely to donate in 2007 seemed to donate more in
general, either by frequency or volume. Their last donation also seemed to be more
recent. The scatter matrix doesn’t reveal much else to my eye. In part 2, I’ll
consider quantitative methods to estimate the strength of these qualitative
observations.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>/project/deep-learning/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0400</pubDate>
      
      <guid>/project/deep-learning/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;

&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;

&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;

&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;

&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>/project/example-external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0400</pubDate>
      
      <guid>/project/example-external-project/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
